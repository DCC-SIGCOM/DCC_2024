{"cells":[{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1728897829500,"user":{"displayName":"DCC_1 SIGCOM","userId":"18270310759855123995"},"user_tz":-540},"id":"aPcNVFCPKm7i"},"outputs":[],"source":["import os\n","import shutil\n","import pandas as pd\n","from collections import defaultdict\n","import numpy as np\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from PIL import Image\n","from torch.utils.data import Dataset, DataLoader\n","from torchvision import transforms, models"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["# GPU 장치 설정\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":557,"status":"ok","timestamp":1728897830056,"user":{"displayName":"DCC_1 SIGCOM","userId":"18270310759855123995"},"user_tz":-540},"id":"QFzxorBsKm7k"},"outputs":[],"source":["# 이미지 파일명에서 성별 및 스타일을 추출하는 함수 (뒤의 W/M으로 성별 구분)\n","def extract_info_from_filename(filename):\n","    # 파일명 예시: \"W_00237_60_popart_W.jpg\"\n","    parts = filename.split('_')\n","    if len(parts) < 4:\n","        return None, None  # 형식이 맞지 않는 파일명은 무시\n","    style = parts[3]  # 스타일 정보는 네 번째 요소\n","    gender = '여성' if parts[-1].startswith('W') else '남성'  # 파일명의 마지막 부분이 성별을 나타냄\n","    return gender, style"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":2,"status":"ok","timestamp":1728897830056,"user":{"displayName":"DCC_1 SIGCOM","userId":"18270310759855123995"},"user_tz":-540},"id":"J-Mt4eBcKm7m"},"outputs":[],"source":["# 디렉토리 내 파일명으로 통계 정보를 추출하는 함수\n","def generate_statistics(directory):\n","    # 성별 & 스타일별 이미지 수를 저장할 딕셔너리\n","    stats = defaultdict(lambda: defaultdict(int))\n","\n","    # 디렉토리 내 모든 파일명에 대해 성별과 스타일 정보 추출\n","    for filename in os.listdir(directory):\n","        if filename.endswith(\".jpg\"):\n","            gender, style = extract_info_from_filename(filename)\n","            if gender and style:\n","                stats[gender][style] += 1\n","\n","    # 통계 정보를 DataFrame으로 변환\n","    stats_list = []\n","    for gender, style_dict in stats.items():\n","        for style, count in style_dict.items():\n","            stats_list.append([gender, style, count])\n","\n","    stats_df = pd.DataFrame(stats_list, columns=['성별', '스타일', '이미지 수'])\n","    return stats_df"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1728897830056,"user":{"displayName":"DCC_1 SIGCOM","userId":"18270310759855123995"},"user_tz":-540},"id":"rpavAJ8SKm7m"},"outputs":[],"source":["# Training 및 Validation 데이터 경로 (경로는 실제 데이터셋 위치로 변경해야 합니다)\n","training_image_dir = '/home/gyuha_lee/DCC2024/dataset/training_image'\n","validation_image_dir = '/home/gyuha_lee/DCC2024/dataset/validation_image'"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":19356,"status":"ok","timestamp":1728897849411,"user":{"displayName":"DCC_1 SIGCOM","userId":"18270310759855123995"},"user_tz":-540},"id":"0gt_sU_gKm7n"},"outputs":[],"source":["# Training 데이터 통계\n","training_stats_df = generate_statistics(training_image_dir)\n","\n","# Validation 데이터 통계\n","validation_stats_df = generate_statistics(validation_image_dir)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":6,"status":"ok","timestamp":1728897849411,"user":{"displayName":"DCC_1 SIGCOM","userId":"18270310759855123995"},"user_tz":-540},"id":"w2F9jTviKm7n","outputId":"9018d399-9ec7-41ee-b6b2-306c4831252d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Training 데이터 통계\n","성별   스타일                  이미지 수\n","----------------------------------\n","남성   metrosexual            278\n","남성   ivy                    237\n","남성   sportivecasual         298\n","남성   mods                   269\n","남성   bold                   268\n","남성   hiphop                 274\n","남성   normcore               364\n","남성   hippie                 260\n","여성   kitsch                  91\n","여성   lounge                  45\n","여성   disco                   37\n","여성   bodyconscious           95\n","여성   sportivecasual         157\n","여성   hippie                  91\n","여성   normcore               153\n","여성   athleisure              67\n","여성   hiphop                  48\n","여성   lingerie                55\n","여성   oriental                78\n","여성   minimal                139\n","여성   feminine               154\n","여성   cityglam                67\n","여성   classic                 77\n","여성   punk                    65\n","여성   genderless              77\n","여성   powersuit              120\n","여성   grunge                  31\n","여성   ecology                 64\n","여성   space                   37\n","여성   military                33\n","여성   popart                  41\n"]}],"source":["# Training 데이터 통계표 출력\n","print(\"Training 데이터 통계\")\n","print(f\"{'성별':<4} {'스타일':<15} {'이미지 수':>10}\")\n","print(\"-\" * 34)\n","for index, row in training_stats_df.iterrows():\n","    print(f\"{row['성별']:<4} {row['스타일']:<15} {row['이미지 수']:>10}\")"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1728897849412,"user":{"displayName":"DCC_1 SIGCOM","userId":"18270310759855123995"},"user_tz":-540},"id":"xthKkkTXND0I","outputId":"a38107ef-3589-400d-bd39-5690a6882eb7"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Validation 데이터 통계\n","성별   스타일                  이미지 수\n","----------------------------------\n","남성   metrosexual             58\n","남성   normcore                51\n","남성   hippie                  82\n","남성   bold                    57\n","남성   ivy                     79\n","남성   mods                    80\n","남성   sportivecasual          52\n","남성   hiphop                  66\n","여성   minimal                 35\n","여성   powersuit               34\n","여성   feminine                44\n","여성   genderless              12\n","여성   disco                   10\n","여성   hippie                  14\n","여성   sportivecasual          48\n","여성   athleisure              14\n","여성   normcore                20\n","여성   bodyconscious           23\n","여성   cityglam                18\n","여성   kitsch                  22\n","여성   classic                 22\n","여성   oriental                18\n","여성   punk                    12\n","여성   ecology                 17\n","여성   military                 9\n","여성   lounge                   8\n","여성   grunge                  10\n","여성   hiphop                   8\n","여성   popart                   8\n","여성   space                   15\n","여성   lingerie                 5\n"]}],"source":["# Validation 데이터 통계표 출력\n","print(\"\\nValidation 데이터 통계\")\n","print(f\"{'성별':<4} {'스타일':<15} {'이미지 수':>10}\")\n","print(\"-\" * 34)\n","for index, row in validation_stats_df.iterrows():\n","    print(f\"{row['성별']:<4} {row['스타일']:<15} {row['이미지 수']:>10}\")"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":4,"status":"ok","timestamp":1728897849412,"user":{"displayName":"DCC_1 SIGCOM","userId":"18270310759855123995"},"user_tz":-540},"id":"FisKzuKRKm7o"},"outputs":[],"source":["# 각각의 통계 정보를 CSV 파일로 저장\n","training_stats_df.to_csv(\"training_image_statistics.csv\", index=False, encoding='utf-8-sig')\n","validation_stats_df.to_csv(\"validation_image_statistics.csv\", index=False, encoding='utf-8-sig')"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/home/gyuha_lee/miniconda3/envs/python311/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/home/gyuha_lee/miniconda3/envs/python311/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=DeepLabV3_ResNet101_Weights.COCO_WITH_VOC_LABELS_V1`. You can also use `weights=DeepLabV3_ResNet101_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n"]}],"source":["# DeepLabV3 모델 로드 (배경 제거용) 및 GPU로 전송\n","deeplab_model = models.segmentation.deeplabv3_resnet101(pretrained=True).eval().to(device)"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# 배경 제거 함수\n","def remove_background(image):\n","    preprocess_transform = transforms.Compose([\n","        transforms.ToTensor(),\n","        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","    ])\n","    \n","    # 이미지를 텐서로 변환하고 GPU로 전송\n","    input_tensor = preprocess_transform(image).unsqueeze(0).to(device)\n","    \n","    with torch.no_grad():\n","        # GPU에서 모델을 실행하여 배경 제거\n","        output = deeplab_model(input_tensor)['out'][0]\n","    \n","    # 결과를 CPU로 전환하여 마스크 생성\n","    output_predictions = output.argmax(0).byte().cpu().numpy()\n","    mask = output_predictions == 15  # DeepLabV3에서 사람 클래스는 15번 클래스\n","    \n","    # 이미지를 numpy 배열로 변환\n","    image_np = np.array(image)\n","    \n","    # 마스크를 이용해 배경 제거\n","    background_removed_image = np.zeros_like(image_np)\n","    background_removed_image[mask] = image_np[mask]\n","    \n","    return Image.fromarray(background_removed_image)\n"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# 원본 이미지 폴더 및 배경 제거된 이미지를 저장할 폴더 경로\n","input_folder = '/home/gyuha_lee/DCC2024/dataset/training_image'  # 원본 이미지 폴더 경로\n","output_folder = '/home/gyuha_lee/DCC2024/dataset/training_image_bg_removed'  # 배경 제거된 이미지 저장 폴더\n","\n","# 출력 폴더가 없으면 생성\n","os.makedirs(output_folder, exist_ok=True)"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["배경 제거 완료 및 저장: /home/gyuha_lee/DCC2024/dataset/training_image_bg_removed/W_01509_00_metrosexual_M.jpg\n"]},{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m image \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(img_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# 배경 제거\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m result_image \u001b[38;5;241m=\u001b[39m remove_background(image)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# 배경 제거된 이미지 저장 경로\u001b[39;00m\n\u001b[1;32m     12\u001b[0m save_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(output_folder, filename)\n","Cell \u001b[0;32mIn[13], line 16\u001b[0m, in \u001b[0;36mremove_background\u001b[0;34m(image)\u001b[0m\n\u001b[1;32m     13\u001b[0m     output \u001b[38;5;241m=\u001b[39m deeplab_model(input_tensor)[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mout\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 결과를 CPU로 전환하여 마스크 생성\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m output_predictions \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39mbyte()\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[1;32m     17\u001b[0m mask \u001b[38;5;241m=\u001b[39m output_predictions \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m15\u001b[39m  \u001b[38;5;66;03m# DeepLabV3에서 사람 클래스는 15번 클래스\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# 이미지를 numpy 배열로 변환\u001b[39;00m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# 폴더 내 모든 이미지에 대해 배경 제거 및 저장\n","for filename in os.listdir(input_folder):\n","    if filename.endswith('.jpg') or filename.endswith('.png'):  # 이미지 파일만 처리\n","        # 이미지 열기\n","        img_path = os.path.join(input_folder, filename)\n","        image = Image.open(img_path).convert('RGB')\n","        \n","        # 배경 제거\n","        result_image = remove_background(image)\n","        \n","        # 배경 제거된 이미지 저장 경로\n","        save_path = os.path.join(output_folder, filename)\n","        \n","        # 배경 제거된 이미지 저장\n","        result_image.save(save_path)\n","\n","        print(f\"배경 제거 완료 및 저장: {save_path}\")\n","\n","print(\"모든 이미지의 배경 제거 완료 및 저장이 완료되었습니다.\")"]},{"cell_type":"code","execution_count":12,"metadata":{},"outputs":[],"source":["# Custom Dataset 클래스 정의 (배경 제거 포함)\n","class CustomFashionDatasetWithBGRemoval(Dataset):\n","    def __init__(self, image_dir, transform=None):\n","        self.image_dir = image_dir\n","        self.transform = transform\n","        self.image_files = [f for f in os.listdir(image_dir) if f.endswith(\".jpg\")]\n","        self.classes = self.get_classes()\n","        \n","    def get_classes(self):\n","        classes = set()\n","        for filename in self.image_files:\n","            gender, style = extract_info_from_filename(filename)\n","            classes.add((gender, style))\n","        return sorted(list(classes))\n","    \n","    def __len__(self):\n","        return len(self.image_files)\n","    \n","    def __getitem__(self, idx):\n","        img_name = self.image_files[idx]\n","        img_path = os.path.join(self.image_dir, img_name)\n","        \n","        image = Image.open(img_path).convert(\"RGB\")\n","        \n","        # 배경 제거 적용\n","        image = remove_background(image)\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        gender, style = extract_info_from_filename(img_name)\n","        label = self.classes.index((gender, style))\n","        \n","        return image, label\n"]},{"cell_type":"code","execution_count":13,"metadata":{},"outputs":[],"source":["# 파일명에서 성별 및 스타일 정보를 추출하는 함수 (뒤의 W/M으로 성별 구분)\n","def extract_info_from_filename(filename):\n","    parts = filename.split('_')\n","    style = parts[3]\n","    gender = '여성' if parts[-1].startswith('W') else '남성'\n","    return gender, style"]},{"cell_type":"code","execution_count":14,"metadata":{},"outputs":[],"source":["# 데이터 전처리 정의\n","transform_train = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.RandomHorizontalFlip(),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","transform_val = transforms.Compose([\n","    transforms.Resize((224, 224)),\n","    transforms.ToTensor(),\n","    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])"]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["train_dataset = CustomFashionDatasetWithBGRemoval(training_image_dir, transform=transform_train)\n","val_dataset = CustomFashionDatasetWithBGRemoval(validation_image_dir, transform=transform_val)"]},{"cell_type":"code","execution_count":21,"metadata":{},"outputs":[],"source":["# DataLoader 설정\n","train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True, num_workers=4)\n","val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False, num_workers=4)"]},{"cell_type":"code","execution_count":22,"metadata":{},"outputs":[],"source":["# ResNet-18 모델 정의\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = models.resnet18(pretrained=False)\n","num_classes = len(train_dataset.classes)\n","model.fc = nn.Linear(model.fc.in_features, num_classes)\n","model = model.to(device)"]},{"cell_type":"code","execution_count":23,"metadata":{},"outputs":[],"source":["# 손실 함수 및 최적화 함수 정의\n","criterion = nn.CrossEntropyLoss()\n","optimizer = optim.Adam(model.parameters(), lr=0.0001)"]},{"cell_type":"code","execution_count":24,"metadata":{},"outputs":[],"source":["# 모델 학습 및 검증 함수\n","def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25):\n","    for epoch in range(num_epochs):\n","        print(f\"Epoch {epoch+1}/{num_epochs}\")\n","        print(\"-\" * 10)\n","        \n","        # 학습 단계\n","        model.train()\n","        running_loss = 0.0\n","        running_corrects = 0\n","        for inputs, labels in train_loader:\n","            inputs, labels = inputs.to(device), labels.to(device)\n","            \n","            optimizer.zero_grad()\n","            \n","            # Forward\n","            outputs = model(inputs)\n","            _, preds = torch.max(outputs, 1)\n","            loss = criterion(outputs, labels)\n","            \n","            # Backward + Optimizer\n","            loss.backward()\n","            optimizer.step()\n","            \n","            running_loss += loss.item() * inputs.size(0)\n","            running_corrects += torch.sum(preds == labels.data)\n","        \n","        epoch_loss = running_loss / len(train_loader.dataset)\n","        epoch_acc = running_corrects.double() / len(train_loader.dataset)\n","        \n","        print(f\"Train Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}\")\n","        \n","        # 검증 단계\n","        model.eval()\n","        val_loss = 0.0\n","        val_corrects = 0\n","        with torch.no_grad():\n","            for inputs, labels in val_loader:\n","                inputs, labels = inputs.to(device), labels.to(device)\n","                \n","                outputs = model(inputs)\n","                _, preds = torch.max(outputs, 1)\n","                loss = criterion(outputs, labels)\n","                \n","                val_loss += loss.item() * inputs.size(0)\n","                val_corrects += torch.sum(preds == labels.data)\n","        \n","        val_loss = val_loss / len(val_loader.dataset)\n","        val_acc = val_corrects.double() / len(val_loader.dataset)\n","        \n","        print(f\"Val Loss: {val_loss:.4f} Acc: {val_acc:.4f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 모델 학습 및 검증\n","train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=25)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# 학습된 모델 저장\n","torch.save(model.state_dict(), 'resnet18_with_bg_removal.pth')"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","machine_shape":"hm","provenance":[]},"kernelspec":{"display_name":"python311","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":0}
